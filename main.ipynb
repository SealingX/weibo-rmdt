{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd03997aacfa674490bea7ea1d35ffcf28c11bd1dfc82d824e1afe9a7b6997aab1f",
   "display_name": "Python 3.7.9 64-bit ('study': virtualenvwrapper)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DatasetBuilder\n",
    "from rmdt import RumorDetector\n",
    "from wbcmt import WbCmtSpider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RumorDetectModel(\n  (origin_bilstm): LSTM(300, 32, batch_first=True, bidirectional=True)\n  (comment_lstm): LSTM(300, 64, batch_first=True)\n  (comment_dropout): Dropout(p=0.5, inplace=False)\n  (attn_U): Linear(in_features=64, out_features=32, bias=False)\n  (attn_W): Linear(in_features=64, out_features=32, bias=False)\n  (attn_v): Linear(in_features=32, out_features=1, bias=False)\n  (linear_dropout): Dropout(p=0.5, inplace=False)\n  (linear): Linear(in_features=128, out_features=2, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "spider = WbCmtSpider(\"_2AkMX_z1ddcPxrAZTnvwQz2ngbYpH-jykKlSrAn7uJhMyAxhu7n8FqSdutBF-XHa3Zsn7ZaBcRYka1AI6UECM-3hy\")\n",
    "builder = DatasetBuilder(\"./data/dict/pretrain_wv.index.json\", \"./data/dict/pretrain_wv.vec.dat\", \"cuda\")\n",
    "detector = RumorDetector(\"cuda\").load(\"./data/model/rmdt.pt\")\n",
    "print(detector.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "【爱鱼生的各位，要小心啦！】原来，日本人从来都不用三文鱼做刺身吃的。蔡澜：\"正统的日本铺子，绝对不会卖三文鱼刺身，因为他们老早知道它的虫极多，只能用盐腌制过后烧熟来吃......三文鱼鱼肉颜色一直保持鲜红，即使腐坏了也不变，又闻不出异味......\" --- 爱鱼生的各位，要小心啦！via实用小百科 \n",
      "473\n"
     ]
    }
   ],
   "source": [
    "origin, comments = spider.get_comments_by_url(\"https://m.weibo.cn/detail/11151379535\")\n",
    "print(origin)\n",
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ljh\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.655 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "[[tensor([[-0.0625, -0.3731,  0.1765,  ..., -0.3938, -0.1949, -0.6888],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1169, -0.3827,  0.2959,  ...,  0.4126,  0.4823,  0.1155],\n",
      "        ...,\n",
      "        [ 0.2251, -0.3518, -0.9442,  ...,  0.5352, -0.0935, -0.5662],\n",
      "        [ 0.3220, -0.2470, -0.2261,  ..., -0.2426,  1.0957,  0.4000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')], [tensor([[-0.2937,  0.1268,  0.0991,  ..., -0.4828,  0.2179,  0.0970],\n",
      "        [-0.1455, -0.1591, -0.0628,  ...,  0.2005,  0.1599, -0.4071],\n",
      "        [ 0.0606, -0.2786, -0.1905,  ...,  0.0537,  0.2374, -0.2926],\n",
      "        ...,\n",
      "        [ 0.0180, -0.0337, -0.1264,  ...,  0.1934,  0.1846, -0.3556],\n",
      "        [ 0.0505,  0.0116, -0.2255,  ...,  0.0495,  0.2931, -0.4102],\n",
      "        [ 0.0718, -0.2632,  0.2791,  ..., -0.0775,  0.1911, -0.5304]],\n",
      "       device='cuda:0')]]\n"
     ]
    }
   ],
   "source": [
    "raw_input = [origin] + comments\n",
    "predict_data = builder.build_input(raw_input)\n",
    "print(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n0.9999988\n[0.8087655  1.0732234  1.0722343  1.073215   1.0732244  1.0732269\n 1.0723962  0.15182693 0.14629532 1.0730348  1.0732291  1.0732286\n 1.0732296  1.073226   1.0676967  0.145288   0.1452541  1.0731877\n 1.0732286  1.0732272  1.0732045  0.14836594 0.14525005 0.14524879\n 1.0722666  1.0732284  1.0732267  1.0731628  0.21869762 0.14525999\n 0.14680582 1.0732197  1.0732294  1.0732293  1.0732294  1.0732296\n 1.0732213  0.14804502 0.14525095 0.1452465  0.14524682 0.1452497\n 0.14524686 0.14524695 0.1491304  1.070177   0.20889574 0.14524758\n 0.14524648 0.8871978  0.17904596 0.1452799  0.14525008 0.14525248\n 1.0731564  1.0732276  1.0732285  1.0732213  1.0730219  1.0730467\n 0.14528053 0.14524867 0.14526357 0.23300937 0.14573924 0.37956044\n 1.0732213  1.0732267  1.0732224  0.31658396 0.1452523  0.14524648\n 1.0646033  1.0732162  1.0732241  1.0728494  0.14525367 0.14524621\n 0.14992896 0.56043154 0.14607315 0.14526002 0.14524633 0.14525127\n 0.14525306 0.14524633 0.1704273  1.0732265  1.0713209  1.0731798\n 1.0732276  1.0704845  0.9765488  0.14525539 0.14526133 0.14918078\n 1.0731213  1.0729693  0.98559654 0.14524974 0.1452473  1.0732083\n 1.0732268  1.0732226  0.21624994 0.14524807 0.1452462  0.14524625\n 0.14524625 1.0544438  1.0732265  1.0732248  1.0732132  0.75663525\n 0.1452548  0.14524633 0.14524643 0.14524698 0.14525022 0.14524698\n 0.14524657 0.14528583 0.40235624 1.0007783  1.0731474  1.0732261\n 1.072876   1.0112427  0.14530557 0.14524665 0.14524645 0.14524758\n 1.0730042  1.0732275  1.0732127  0.42824757 0.62609667 0.14536156\n 0.96046215 1.0725682  1.0732267  1.065245   0.14619428 0.14524741\n 0.14524676 0.16777967 1.0731679  1.0236444  0.15093675 1.0732219\n 1.0671746  0.14532168 0.14524734 0.14524625 0.14525387 0.14526127\n 1.0596458  1.0732288  1.0732285  1.0732286  1.0731821  0.54450715\n 0.14525105 0.14524637 0.14524722 0.14524683 0.14819235 0.7717389\n 1.0732291  1.0732276  1.0732288  1.0732191  1.0732286  1.0676936\n 0.1606371  0.14524828 0.14524706 0.14524637 0.1452468  0.97339594\n 1.0732199  1.0732244  0.93761694 0.14524747 0.14524613 0.1452464\n 0.14524667 0.1452469  0.18236046 1.0624372  0.14525266 0.14524609\n 0.14524621 0.14526673 1.0732216  1.0732285  1.0732293  1.0732296\n 1.0732291  0.9419736  0.1453614  0.14524738 0.14524636 0.14524613\n 0.14524609 0.14524685 0.14524657 0.14524618 0.14524609 0.14524613\n 0.14524609 0.14524609 0.1452465  0.14524683 0.14524648 0.14533894\n 1.0732052  1.0728248  0.14548098 0.14524621 0.14524607 0.1452465\n 0.14524633 0.14524613 0.14524609 0.14524618 0.14525005 0.14524633\n 0.14524621 0.14524633 0.14524643 0.1452497  1.0710676  1.0732268\n 1.0731896  1.0382893  0.14526938 0.14524633 0.14524621 0.14776576\n 0.9903975  0.14555638 0.14525008 1.0728159  1.0732262  1.0732298\n 1.0732297  1.0732293  1.0732286  1.0731933  0.14539407 0.14524941\n 0.14524637 0.14524625 0.14524703 0.14524633 0.14525329 1.0604914\n 0.14527985 0.14524657 0.14524664 0.14524637 0.14524609 0.14524609\n 0.14524616 0.14524609 0.14524943 1.0705323  1.0665208  0.14528188\n 0.14524621 0.14527209 0.15322185 0.1452468  0.14525777 0.14531268\n 0.1452703  0.15507607 1.0731596  1.0730681  1.0732238  1.0591094\n 1.0732245  1.0732207  0.3411745  1.0528736  0.99540454 0.85477304\n 1.0587342  0.14545825 0.14529777 0.14524695 0.14524627 0.14524633\n 0.14524636 0.14524627 0.14524625 0.14524797 0.14527038 0.14551942\n 0.14524657 0.14524668 1.0548496  1.0732254  1.0732268  1.0732285\n 1.0732298  1.0732296  1.0732286  1.0732244  0.1477144  0.14524984\n 0.14525013 0.14524806 0.1452467  0.14810969 1.073217   1.073228\n 1.0732279  1.0687221  0.14525636 0.14524618 0.14524613 0.14524607\n 0.14524662 0.14581618 0.14757301 0.14525078 0.14524627 0.1452469\n 0.1461634  0.14525203 0.14524637 0.14524618 0.14524657 0.14524645\n 0.14524643 0.14539632 1.0732257  1.0732292  1.0732286  1.0732291\n 1.0732229  1.0732263  0.17854233 0.14524832 0.14524618 0.14524627\n 0.14529878 0.18101351 1.0648197  0.14629456 0.14524764 0.14524613\n 0.14551182 1.073226   1.0732263  1.0731769  0.14680648 0.15990315\n 0.14526725 0.14524654 0.14524621 0.1452462  0.14524625 0.14524616\n 0.14524977 0.14524686 0.14524733 0.14524637 0.14524607 0.14524607\n 0.14524618 0.14773048 1.0728488  0.18963642 0.14525002 0.14524609\n 0.14524704 0.14524633 0.1452518  0.14524661 0.93364984 1.0729107\n 0.14545876 0.1454298  1.0730952  1.0732285  1.0732288  1.0730039\n 0.15102929 0.14525016 0.14524636 0.14525099 0.1452541  0.14524749\n 0.14524618 0.14524704 1.0720363  1.0732286  1.0732276  1.0732297\n 1.0732293  1.0658827  0.14554553 0.1452486  0.1452466  0.1452462\n 0.14524616 0.1452469  0.1452524  1.0731091  1.0732285  1.0732275\n 1.0732286  1.073227   0.31937078 0.14525041 0.14524633 0.14524613\n 0.14524609 0.14524607 0.14524618 1.0716585  1.0731426  1.0732113\n 0.618914   0.14524688 0.14524607 0.14543656 0.2295631  1.0638107\n 0.14578326 0.14524749 0.14524625 0.1452473  0.14525117 0.14650066\n 1.0732219  1.0732272  1.0732219  0.7854418  0.14524765 0.1452462\n 0.14524609 0.14524616 0.14524609 0.14524609 0.14524609 0.14524607\n 0.14524609 0.14524613 0.14524794 0.14524627 0.14524637 0.14524832\n 0.1452635  0.14525002 0.14524627 0.14524618 0.14524607 0.1453495\n 1.0732175  1.0732279  1.0732274  1.0732273  1.0732262  0.9995175\n 1.0716691  0.14555854 0.1452513  0.14524657 0.14524628]\n"
     ]
    }
   ],
   "source": [
    "result = detector.predict(predict_data)\n",
    "print(result[\"label\"])\n",
    "print(result[\"prob\"])\n",
    "print(result[\"weight\"])"
   ]
  }
 ]
}